<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <title>PartSLAM: Unsupervised Part-based Scene Modeling for Fast Succinct Map Matching - IROS 2013 </title>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 40px;
      background-color: #ffffff;
      color: #000000;
      line-height: 1.6;
    }
    h1 {
      font-size: 26px;
      font-weight: bold;
    }
    h2 {
      font-size: 22px;
      margin-top: 30px;
      border-bottom: 2px solid #007acc;
      padding-bottom: 5px;
    }
    .authors {
      font-size: 16px;
      margin-bottom: 20px;
    }
    .abstract {
      background-color: #f0f0f0;
      padding: 20px;
      border-left: 5px solid #007acc;
      margin-bottom: 30px;
    }
    .abstract p {
      margin-bottom: 15px;
    }
    .links a {
      display: inline-block;
      margin-right: 15px;
      color: #007acc;
      text-decoration: none;
    }
    .bibtex {
      background-color: #f9f9f9;
      padding: 15px;
      font-family: monospace;
      white-space: pre-wrap;
      border: 1px solid #ccc;
      margin-bottom: 30px;
    }
    .images {
      display: flex;
      flex-wrap: wrap;
      gap: 20px;
      margin-top: 20px;
    }
    .images img {
      max-width: 50%;
      height: auto;
      border: 1px solid #ccc;
    }
    .keywords {
      background-color: #f9f9f9;
      padding: 10px;
      border: 1px dashed #007acc;
      margin-bottom: 30px;
    }
  </style>
</head>
<body>

  <h1>PartSLAM: Unsupervised Part-based Scene Modeling for Fast Succinct Map Matching</h1>

  <div class="authors">
    Hanada Shogo, Tanaka Kanji  </div>

  <h2>Keywords</h2>
  <div class="keywords">
    
  </div>

  <h2>Abstract</h2>
  <div class="abstract">
    <p>In this paper, we explore the challenging 1-to-N map matching problem, which exploits a compact description of map data, to improve the scalability of map matching techniques used by various robot vision tasks. We propose a first method explicitly aimed at fast succinct map matching, which consists only of map-matching subtasks. These tasks include offline map matching attempts to find a compact part-based scene model that effectively explains each map using fewer larger parts. The tasks also include an online map matching attempt to efficiently find correspondence between the partbased maps. Our part-based scene modeling approach is unsupervised and uses common pattern discovery (CPD) between the input and known reference maps. This enables a robot to learn a compact map model without human intervention. We also present a practical implementation that uses the state-of-theart CPD technique of randomized visual phrases (RVP) with a compact bounding box (BB) based part descriptor, which consists of keypoint and descriptor BBs. The results of our challenging map-matching experiments, which use a publicly available radish dataset, show that the proposed approach achieves successful map matching with significant speedup and a compact description of map data that is tens of times more compact. Although this paper focuses on the standard 2D pointset map and the BB-based part representation, we believe our approach is sufficiently general to be applicable to a broad range of map formats, such as the 3D point cloud map, as well as to general bounding volumes and other compact part representations.</p>
  </div>

  <h2>Related document</h2>
  <div class="links">
    <a href="https://arxiv.org/pdf/2306.10782">[PDF]</a>
    <a href="補足資料へのリンク">[Supplementary]</a>
    <a href="https://arxiv.org/abs/2306.10782">[arXiv]</a>
    <a href="コードへのリンク">[Code]</a>
  </div>

  <h2>BibTeX</h2>
  <div class="bibtex">
@inproceedings{DBLP:conf/iros/ShogoK13,
  author       = {Shogo Hanada and
                  Kanji Tanaka},
  title        = {PartSLAM: Unsupervised part-based scene modeling for fast succinct
                  map matching},
  booktitle    = {2013 {IEEE/RSJ} International Conference on Intelligent Robots and
                  Systems, {IROS} 2013, Tokyo, Japan, November 3-7, 2013},
  pages        = {1582--1588},
  publisher    = {{IEEE}},
  year         = {2013},
  url          = {https://doi.org/10.1109/IROS.2013.6696560},
  doi          = {10.1109/IROS.2013.6696560},
  timestamp    = {Thu, 28 Sep 2023 20:45:52 +0200},
  biburl       = {https://dblp.org/rec/conf/iros/ShogoK13.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
  </div>

  <h2>図表・写真</h2>
  <div style="text-align: left;">
      <img src="../images_file/PartSLAM/image1.png" alt="Fig1" style="max-width: 60%;">
      <p>Fig. 1. Compared to existing direct map matching (“dMM”) methods, our method indirectly matches between the local map and each of the global maps,
        while using a known reference map as the intermediary. In offline work, a common pattern discovery (“CPD”) process translates an input local/global
        map to a compact part-based map descriptor (“MD”), by extracting representative parts (colored bounding boxes) that effectively explain an input map
        from a known reference map. In online work, a descriptor matcher (“DM”) rapidly matches between the compact part-based maps.
    </p></div>
  
  <div style="text-align: left;">
      <img src="../images_file/PartSLAM/image2.png" alt="Fig2" style="max-width: 60%;">
      <p>Fig. 2. Three types of map matching schemes considered in this study: direct map matching (dMM), indirect map matching (iMM) and hybrid map matching (hMM). 
        The dMM scheme directly matches between a given map pair, while the iMM and the hMM schemes match in an indirect manner using a given dictionary map as intermediate. 
        While iMM deals with a situation where only the compact map descriptors are available, hMM addresses a situation where the original local map data is available.
    </p></div>

  <div style="text-align: left;">
      <img src="../images_file/PartSLAM/image3.png" alt="Fig3" style="max-width: 60%;">
      <p>Fig. 3. Datasets used for experiments. “abuilding”, “albert”, “claxton”, “fr079”, “run101”, and “kwing” from radish dataset [13] are used as the dictionary maps. 
        “Local/global maps” are several samples from local and global maps.
      </p></div>
  
  <div style="text-align: left;">
      <img src="../images_file/PartSLAM/image4.png" alt="Fig4" style="max-width: 60%;">
      <p>Fig. 4. Results of part-based scene modeling. For each panel, the top subpanel shows the input local map, while the middle and the bottom subpanels
        respectively illustrate the representative parts discovered w.r.t. the local and the global maps. In each figure, the white dots indicate point cloud
        in the map, and the colored rectangles indicate bounding boxes that crop the representative parts.
      </p></div>

  <div style="text-align: left;">
      <p><strong>Table1：</strong>SUMMARY OF ANR PERFORMANCE.</p>
      <img src="../images_file/PartSLAM/table1.png" alt="Table1" style="max-width: 45%;">
      <p>The Data ID #1-#5 correspond to ANR for global map database from “fr101”, “abuilding”, “albert”, “kwing” and “fr079”, where “fr079”, “fr101”, “run”,
        “claxton2” and “albert” are respectively used as dictionary map. The colored fonts and the bold-face fonts respectively represent the best 5 methods
        and the best method for each data.
      </p></div>

  <div style="text-align: left;">
      <img src="../images_file/PartSLAM/image5.png" alt="Fig5" style="max-width: 60%;">
      <p>Fig. 5. Normalized rank for each strategy.
      </p></div>

</body>
</html>
