<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <title>論文タイトル - CVPR 2024</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 40px;
      background-color: #ffffff;
      color: #000000;
    }
    h1 {
      font-size: 24px;
      font-weight: bold;
    }
    h2 {
      font-size: 20px;
      margin-top: 30px;
    }
    .authors {
      font-size: 16px;
      margin-bottom: 20px;
    }
    .abstract {
      background-color: #f0f0f0;
      padding: 15px;
      border-left: 5px solid #007acc;
      margin-bottom: 30px;
    }
    .links a {
      display: inline-block;
      margin-right: 15px;
      color: #007acc;
      text-decoration: none;
    }
    .bibtex {
      background-color: #f9f9f9;
      padding: 15px;
      font-family: monospace;
      white-space: pre-wrap;
      border: 1px solid #ccc;
    }
  </style>
</head>
<body>

  <h1>Fine-Grained Self-Localization from Coarse Egocentric Topological Maps</h1>

  <div class="authors">
    Daiki Iwata, Kanji Tanaka, Mitsuki Yoshida, Ryogo Yamamoto, Yuudai Morishita and Tomoe Hiroki
  </div>

  <h2>アブストラクト</h2>
  <div class="abstract">
    Topological maps are increasingly favored in robotics for their cognitive relevance, compact storage, and ease of transferability to human users. While these maps provide scalable solutions for navigation and action planning, they present challenges for tasks requiring fine-grained self-localization, such as object goal navigation. This paper investigates the action planning problem of active self-localization from a novel perspective: can an action planner be trained to achieve fine-grained self-localization using coarse topological maps? Our approach acknowledges the inherent limitations of topological maps; overly coarse maps lack essential information for action planning, while excessively high-resolution maps diminish the need for an action planner. To address these challenges, we propose the use of egocentric topological maps to capture fine scene variations. This representation enhances self-localization accuracy by integrating an output probability map as a place-specific score vector into the action planner as a fixed-length state vector. By leveraging sensor data and action feedback, our system optimizes self-localization performance. For the experiments, the de facto standard particle filter-based sequential self-localization framework was slightly modified to enable the transformation of ranking results from a graph convolutional network (GCN)-based topological map classifier into real-valued vector state inputs by utilizing bag-of-place-words and reciprocal rank embeddings. Experimental validation of our method was conducted in the Habitat workspace, demonstrating the potential for effective action planning using coarse maps.
  </div>

  <h2>関連資料</h2>
  <div class="links">
    <a href="論文PDFへのリンク">[PDF]</a>
    <a href="補足資料へのリンク">[Supplementary]</a>
    <a href="arXivへのリンク">[arXiv]</a>
    <a href="コードへのリンク">[Code]</a>
  </div>

  <h2>BibTeX</h2>
  <div class="bibtex">
@inproceedings{DBLP:conf/visigrapp/Iwata0YYYT25,
  author       = {Daiki Iwata and
                  Kanji Tanaka and
                  Mitsuki Yoshida and
                  Ryogo Yamamoto and
                  Morishita Yuudai and
                  Hiroki Tomoe},
  editor       = {Thomas Bashford{-}Rogers and
                  Daniel Meneveaux and
                  Mehdi Ammi and
                  Mounia Ziat and
                  Stefan J{\"{a}}nicke and
                  Helen C. Purchase and
                  Petia Radeva and
                  Antonino Furnari and
                  Kadi Bouatouch and
                  A. Augusto de Sousa},
  title        = {Fine-Grained Self-Localization from Coarse Egocentric Topological
                  Maps},
  booktitle    = {Proceedings of the 20th International Joint Conference on Computer
                  Vision, Imaging and Computer Graphics Theory and Applications, {VISIGRAPP}
                  2025 - Volume 2: VISAPP, Porto, Portugal, February 26-28, 2025},
  pages        = {810--819},
  publisher    = {{SCITEPRESS}},
  year         = {2025},
  url          = {https://doi.org/10.5220/0013098000003912},
  doi          = {10.5220/0013098000003912},
  timestamp    = {Tue, 15 Apr 2025 11:34:20 +0200},
  biburl       = {https://dblp.org/rec/conf/visigrapp/Iwata0YYYT25.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
  </div>

</body>
</html>

